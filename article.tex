%  LaTeX support: latex@mdpi.com 
%  In case you need support, please attach all files that are necessary for compiling as well as the log file, and specify the details of your LaTeX setup (which operating system and LaTeX version / tools you are using).

% You need to save the "mdpi.cls" and "mdpi.bst" files into the same folder as this template file.

%=================================================================
\documentclass[entropy,article,submit,moreauthors,pdftex,10pt,a4paper]{mdpi} 
\usepackage{subfigure} 


%
%--------------------
% Class Options:
%--------------------
% journal
%----------
% Choose between the following MDPI journals:
% actuators, admsci, aerospace, agriculture, agronomy, algorithms, animals, antibiotics, antibodies, antioxidants, applsci, arts, atmosphere, atoms, axioms, batteries, behavsci, beverages, bioengineering, biology, biomedicines, biomimetics, biomolecules, biosensors, brainsci, buildings, carbon, cancers, catalysts, cells, challenges, chemosensors, children, chromatography, climate, coatings, computation, computers, condensedmatter, cosmetics, cryptography, crystals, data, dentistry, designs, diagnostics, diseases, diversity, econometrics, economies, education, electronics, energies, entropy, environments, epigenomes, fermentation, fibers, fishes, fluids, foods, forests, futureinternet, galaxies, games, gels, genealogy, genes, geosciences, geriatrics, healthcare, horticulturae, humanities, hydrology, informatics, information, infrastructures, inorganics, insects, instruments, ijerph, ijfs, ijms, ijgi, ijtpp, inventions, jcdd, jcm, jdb, jfb, jfmk, jimaging, jof, jintelligence, jlpea, jmse, jpm, jrfm, jsan, land, languages, laws, life, literature, lubricants, machines, magnetochemistry, marinedrugs, materials, mathematics, mca, mti, medsci, medicines, membranes, metabolites, metals, microarrays, micromachines, microorganisms, minerals, molbank, molecules, mps, nanomaterials, ncrna, neonatalscreening, nutrients, particles, pathogens, pharmaceuticals, pharmaceutics, pharmacy, philosophies, photonics, plants, polymers, processes, proteomes, publications, recycling, religions, remotesensing, resources, risks, robotics, safety, sensors, separations, sexes, sinusitis, socsci, societies, soils, sports, standards, sustainability, symmetry, systems, technologies, toxics, toxins, tropicalmed, universe, urbansci, vaccines, vetsci, viruses, water
%---------
% article
%---------
% The default type of manuscript is article, but can be replaced by: 
% addendum, article, book, bookreview, briefreport, casereport, changes, comment, commentary, communication, conceptpaper, correction, conferenceproceedings, conferencereport, expressionofconcern, meetingreport, creative, datadescriptor, discussion, editorial, essay, erratum, hypothesis, interestingimage, letter, newbookreceived, opinion, obituary, projectreport, reply, retraction, review, preprints, shortnote, supfile, technicalnote
% supfile = supplementary materials
%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g. the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.
%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.
%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. If eps figure are used, remove the option pdftex and use LaTeX and dvi2pdf.

%=================================================================
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother 
\articlenumber{x}
\doinum{10.3390/------}
\pubvolume{xx}
\pubyear{2017}
\copyrightyear{2017}
\externaleditor{Academic Editor: name}
\history{Received: date; Accepted: date; Published: date}

%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, calc, indentfirst, fancyhdr, graphicx, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, amsthm, hyphenat, natbib, hyperref, footmisc, geometry, caption, url, mdframed

%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Remark, Definition
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Histogram of Gradient Orientations of Signal Plots applied to P300 Detection}

% Authors, for the paper (add full first names)
\Author{Rodrigo Ramele $^{1}$*, Ana Julia Villar $^{1}$ and Juan Miguel Santos  $^{1}$}
% Authors, for metadata in PDF
\AuthorNames{Rodrigo Ramele, Ana Julia Villar and Juan Miguel Santos}

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address[1]{%
$^{1}$ \quad Computer Engineering Department, Instituto Tecnológico de Buenos Aires (ITBA); info@itba.edu.ar}

% Contact information of the corresponding author
\corres{Correspondence: rramele@itba.edu.ar; Tel.: +54-11-2150-4800(5834)}

% Current address and/or shared authorship  COMMENTED PER REVIEWER
%\firstnote{Current address: C1437FBH Lavarden 315, Ciudad Autónoma de Buenos Aires, Argentina} 

%\firstnote{.} 

% Simple summary
%\simplesumm{}

% Abstract (Do not use inserted blank lines, i.e. \\) 
\abstract{The analysis of Electroencephalographic (EEG) signals is of ulterior importance to elucidate patterns that could improve the implementation of Brain Computer Interfaces (BCI). These systems are meant to provide alternative pathways to transmit volitional information which could potentially enhance the quality of life of patients affected by neurodegenerative disorders or improve Human Computer Interaction systems.  Of particular interests are those which are based on the recognition of Event-Related Potentials (ERP) because they can be elicited by external stimuli and used to implement spellers, to control external devices or even avatars in virtual reality environments.  This work mimics what electroencephalographers have been doing clinically, visually inspecting and categorizing phenomena within the EEG by the extraction of features from the images of the plots of the signals.  It also aims to provide a framework to analyze, characterize and classify EEG signals, with a focus on the P300, an ERP elicited by the oddball paradigm of rare events.  The validity of the method is shown by offline processing a public dataset of Amyotrophic Lateral Sclerosis (ALS) patients and an own dataset for healthy subjects.}

% Keywords
\keyword{EEG; BCI; P300; ALS; NBNN; HGOSP; SIFT}

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}
%\AMS{}

% If this is an expanded version of a conference paper, please cite it here: enter the full citation of your conference paper, and add $^\S$ in the end of the title of this article.
%\conference{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data:

%\dataset{DOI number or link to the deposited data set in cases where the data set is published or set to be published separately. If the data set is submitted and will be published as a supplement to this paper in the journal Data, this field will be filled by the editors of the journal. In this case, please make sure to submit the data set as a supplement when entering your manuscript into our manuscript editorial system.}

%\datasetlicense{license under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% For Conference Proceedings Papers: add the conference title here
%\conferencetitle{}

%\setcounter{secnumdepth}{4}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Only for the journal Gels: Please place the Experimental Section after the Conclusions

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{section}{-1} %% Remove this when starting to work on the template.

\section{Introduction}

Although recent advances in neuroimagining techniques (particularly radio-nuclear and radiological scanning methods) \citep{Schomer2010} have diminished the prospects of the traditional Electroencephalography (EEG), the advent and development of digitized devices has pressed for a revamping of this hundred years old technology.  Their versatility, ease of use, temporal resolution, ease of development and fabrication, and its proliferation as consumer devices, are pushing EEG to become the de-facto non invasive portable or ambulatory method to access and harness brain information~\cite{DeVos2014}.

A key contribution to this expansion has been the field of Brain Computer Interfaces (BCI)~\citep{WolpawJonathanR2012} which is the pursuit of the development of a new channel of communication particularly aimed to persons affected by neurodegenerative diseases.

One noteworthy aspect of this novel communication channel is the ability to transmit information from the Central Nervous System (CNS) to a computer device and from there use that information to control a wheelchair~\citep{Carlson2013}, as input to a speller application~\citep{Guger2009a}, in a Virtual Reality environment~\citep{Lotte2013} or as aiding tool in a rehabilitation procedure~\citep{Jure2016}.  The holly grail of BCI is to implement a new complete and alternative pathway to restore lost locomotion~\citep{WolpawJonathanR2012}.

EEG signals are remarkably complex and have been characterized as a multichannel non-stationary stochastic process.  Additionally, they have high variability between different subjects and even between different moments for the same subject, requiring adaptive and co-adaptive calibration and learning procedures \citep{Clerc}.  Hence, this imposes an outstanding challenge that is necessary to overcome in order to extract information from raw EEG signals.

Moreover, EEG markers~\citep{Clerc} that can be used to  transmit volitional information are limited, and each one of them has a particular combination of appropriate methods to decode them. Inevitably, it is necessary to implement  distinct and specialized algorithmic methods, to filter the signal, enhance its Signal to Noise Ratio (SNR), and try to determine some meaning out of it.  

BCI has gained mainstream public awareness with worldwide challenge competitions like Cybathlon~\citep{Riener2014} and even been broadcasted during the inauguration ceremony of the 2014 Soccer World Cup.  New developments have overcome the out-of-the-lab high-bar and they are starting to be used in real world environments~\citep{Guger2017,Huggins2016}.  However, they still lack the necessary robustness, and its performance is well behind any other method of human computer interaction, including any kind of detection of residual muscular movement~\citep{Clerc}.

A few works have explored the idea of exploiting the signal waveform to analyze the EEG signal.  In~\citep{Alvarado-Gonzalez2016} an approach based on Slope Horizontal Chain Code is presented, whereas in ~\citep{Yamaguchi2009} a similar procedure was implemented based on Mathematical Morphological Analysis.  The seminal work of Bandt-Pompe Permutation Entropy~\citep{Berger2017} also explores succinctly this idea as a basis to establish the time series ordinal patterns.  In the article~\citep{Ramele2016},  the authors introduce a method for classification of rhythmic EEG events like Visual Occipital Alpha Waves  and Motor Imagery rolandic central $\mu$ rhythms using the histogram of gradient orientations of signal plots.  Inspired in that work, we propose a novel application of the developed method to classify and describe transient events, particularly the P300 Event Related Potential.  
The proposed approach is based on the waveform analysis of the shape of the EEG signal, but using histogram of gradient orientations. The method is built by mimicking what traditionally electroencephalographers have been performing for almost a century: visually inspecting raw signal plots, as it is described in~\citep{Hartman2005}.

This paper reports a method to, (1) classify P300 signals based on the identification of their structure in the shape domain using histograms of gradient orientations extracted from the image of signal plots, and (2) describe the way in which this classification can be used to implement an offline P300-based BCI Speller application using two public datasets. Its validity is verified by processing offline data for ALS patients and for healthy subjects. 

This article unfolds as follows: Section~\ref{Feature} is dedicated to explain the Feature Extraction method based on Histogram of Gradient Orientations of the Signal Plot: Section~\ref{Pipeline} shows the preprocessing pipeline,  Section~\ref{Plot}  describes the image generation of the signal plot, Section~\ref{SIFT}  presents the feature extraction procedure while  Section~\ref{Classification}  introduces the whole  Speller Matrix Letter Identification procedure including the classification algorithm based on Naive Bayes Nearest Neighbor (NBNN)~\citep{Boiman2008}. In Section~\ref{Protocol}, the experimental protocol is expounded. Section~\ref{Results} shows the results of applying the proposal technique and a discussion is presented. 
In the final Section~\ref{conclusion}  we expose our remarks, conclusions and future work.
%This kind of EEG events are described in~\citep{Hartman2005} and~\citep{Ben-Simon2013}.

\section{Materials and Methods}

The P300~\citep{Farwell1988,Knuth2006} is a positive deflection of the EEG signal which occurs around $300$ ms after the onset of a rare and deviant stimulus that the subject is expected to attend.  It is produced under the oddball paradigm~\cite{WolpawJonathanR2012} and it is consistent across different subjects. It has a lower amplitude  ($\pm 5 \mu V $) compared to basal EEG activity, reaching a SNR of around $-15$ db estimated based on the amplitude of the P300 response signal divided by the standard deviation of the background EEG activity~\citep{Hu2010}.  This signal can be used to implement a speller application by means of a Speller Matrix~\citep{Farwell1988}. Fig.~\ref{fig:p300matrix} shows an example of the Speller Matrix used in the OpenVibe Open Source software~\citep{Renard2010}, where the flashes of rows and columns provide the deviant stimulus required to elicit this physiological response.   Each time a row or a column that contains the desired letter flashes, the corresponding synchronized EEG signal should also contain the P300 signature and by detecting it, the selected letter can be identified.

\begin{figure}[H]
\centering
\subfigure[Row flash.]{\includegraphics[width=.29\linewidth]{openvibep300matrix.png}}
\subfigure[Column flash.]{\includegraphics[width=.29\linewidth]{p300matrixcoloriginal.png}}
\caption{Example of the $6 \times 6$ Speller Matrix used in the study.  Rows and columns flash intermittently in random permutations.}
\label{fig:p300matrix}
\end{figure}

\subsection{Feature Extraction based on Histogram of Gradient Orientations of the Signal Plot} \label{Feature}

In this section, the signal preprocessing, the method for generating images from signal plots, the feature extraction procedure and the speller matrix identification are described. 

\subsubsection{Preprocessing Pipeline} \label{Pipeline}

\begin{itemize}
\item \textbf{Signal Enhancement}: The preprocessing stage consists of the enhancement of the SNR of the P300 pattern above the level of basal EEG. The processing pipeline starts by applying a notch filter to the raw digital signal, a 
$4$th degree $10$ Hz lowpass Butterworth filter and finally a decimation with a Finite Impulse Response (FIR) filter of order $30$ from the original sampling frequency down to $16$ Hz \citep{Krusienski2006}.
\item \textbf{Artifact Removal}: The EEG signal matrix is processed on a channel by channel basis.   For every 12 flashing stimuli, i.e. one complete sequence of intensification of each of the $6$ rows plus the $6$ columns, a basic artefact elimination procedure is implemented by removing the entire sequence when any signal deviates above/bellow $ \pm 70 \mu V $.
\item \textbf{Segmentation}: For each of the $12$ stimuli,  a window of $t_{max} = 1$ second of the multichannel signal is extracted, starting from the stimulus onset, corresponding to each row/column intensification.  Two of these segments should contain the P300 ERP signature time-locked to the flashing stimulus, one for the row, and one for the column.
\item \textbf{Signal Averaging}:  The P300 ERP is deeply buried under background EEG so the traditional approach to identify it is by point-to-point averaging the time-locked stacked signal segments.  Hence the values which are not related to, and not time-locked to the onset of the stimulus are canceled out~\citep{Liang2008}. 
\end{itemize}

This last step determines the operation of any P300 Speller.  In order to obtain an improved signal in terms of its SNR, repetitions of the sequence of row/column intensification are necessary.  And, at the same time, as long as more repetitions are needed, the ability to transfer information faster is diminished, so there is a trade-off that must be acutely determined.

\subsubsection{Signal Plotting} \label{Plot}

Averaged signal segments are standardized and scaled by 

\begin{equation}
\tilde{x}(n,c) = \left \lfloor{ \gamma \cdot \frac{( x(n,c) - \bar{x}(c)  )}{ \sigma(c) } }\right \rfloor, n \in \{ 1, \dots, n_{max}\},c \in \{1,2,\dots,Ch\}
\label{eq:standarizedaverages}
\end{equation}

\noindent where $\gamma > 0$ is an input parameter of the algorithm and  it is related with the image scale. In addition, $ x(n,c) $ is the point-to-point averaged EEG matrix for the sample point $n$ and for channel $c$, $n_{max}=F_s.t_{max}$ and $F_s$ is the sampling frequency. The parameter  $Ch$ is the number of available EEG channels. Lastly, $$\bar{x}(c) =\frac{1}{n_{max}}\sum_{n=1}^{n_{max}}x(n,c)$$ and $$ \sigma(c) = (\frac{1}{n_{max}-1}\sum_{n=1}^{n_{max}}(x(n,c)-\bar{x}(c))^2 )^{\frac{1}{2}}$$ are the mean and standard deviation of $x(n,c), n \in 1,\dots,n_{max}$, for each channel $c$.

Consequently, the image is constructed by placing the sample points according to

\begin{equation}
I(z_1,z_2) = \left\{ \begin{array}{rl}
255 & \text{if} \,  z_1 = \gamma \cdot n; \; z_2 = \tilde{x}(n,c) + z(c) \\
0   & \mbox{otherwise}
\end{array}\right.
\label{eq:images}
\end{equation}

\noindent where $ (z_1,z_2) \in \mathbb{N} \times \mathbb{N}$ iterate over the width (based on the length of the signal segment) and height (based on the peak-to-peak amplitude) of the newly created image,  $n \in \{1, \dots, n_{max}\}$ and $c \in \{1,2,\dots,Ch\}$.  The function $z(c)$, $c \in \{1,2,\dots,Ch\}$ is the location on the image where the signal's zero value has to be located in order to fit the entire signal within the image:

\begin{equation}
z(c) = \left \lfloor{ \frac{\max_{1 \leq n\leq n_{max}} \tilde{x}(n,c)  - \min_{1 \leq n\leq n_{max}} \tilde{x}(n,c) }{2} }\right \rfloor -   \left \lfloor{ \frac{\max_{1 \leq n\leq n_{max}} \tilde{x}(t,c)  + \min_{1 \leq n\leq n_{max}} \tilde{x}(n,c)}{ 2} }\right \rfloor
\label{eq:zerolevel}
\end{equation}
  
In order to complete the plot from the pixels, the Bresenham \citep{Bresenham1965,Ramele2016} algorithm is used to interpolate straight lines between each pair of  consecutive pixels.


\subsubsection{Feature Extraction: Histogram of Gradient Orientations}
\label{SIFT}

%is calculated on local image patches centered on sample points \citep{Vedaldi2010}.

On the generated image $I$, a keypoint $\mathbf{kp}$ is placed on a pixel $(x_{kp}, y_{kp})$ over the image plot and a window around the keypoint is considered. A local image patch of size $S_p \times S_p$ pixels is constructed by dividing the window in $16$ blocks of size $3s$ each one,  where $s$ is the scale of the local patch and it is an input parameter of the algorithm. It is arranged in a $4 \times 4$ grid and the pixel $ \mathbf{kp}$ is the patch center, thus $S_p = 4.3s $ pixels. 

A local representation of the shape of the signal within the patch can be described by obtaining the gradient orientations on each of the $16$ blocks and creating a histogram of gradients.  This technique is based on Lowe's SIFT~\citep{Lowe2004} method, and it is biomimetically inspired in how the visual cortex detects shapes by analyzing orientations.   In order to calculate the histogram, the interval $[0-360]$ of possible angles is divided in $8$ bins, each one at $45$ degrees.

 For each spacial bin $ i,j = \{1,2,3,4\} $, corresponding to the indexes of each block $B_{i,j}$,  the orientations are accumulated in a  $3$-dimensional histogram $h$ through the following equation: 
 

\begin{equation}
 h(\theta,i,j) = 3s \sum_{\mathbf{x} \in B_{i,j}} w_\mathrm{ang}(\angle J(\mathbf{x}) - \theta)\, w_{ij}\left(\frac{\mathbf{x} - \mathbf{kp}}{3 s}\right)\, |J(\mathbf{x})|
\label{eq:histogram}
\end{equation}

\noindent  where $\mathbf{x}$ is a pixel from  the $i,j$-block $B_{i,j}$, $ i,j \in \{1,2,3,4\} $, $ \theta \in \{0, 45, 90, 135, 180, 225, 270, 315\} $,  $ |J(\mathbf{x})| $ is the norm of the gradient vector in the pixel $\mathbf{x}$ and it is computed using finite differences, $\angle J(\mathbf{x}) $ is the angle of the gradient vector,  $\theta$ is the angle bin,   and $ w_\mathrm{ang}(\cdot) $  and $ w_{ij}(\cdot) $ are linear interpolation functions used by Lowe and Vedaldi et al. in~\citep{Lowe2004,Vedaldi2010}.  Lastly, the fixed value of $ 3 $ is a magnification factor which corresponds to the number of pixels per each block when $s = 1$.  As the patch has  $16$ blocks and  $8$ bin angles are considered, a descriptor of $128$ dimension is obtained. It can be observed that in each step, the histogram is computed by multiplying by $ |J(\mathbf{x})| $, so the method considers both, the magnitude and the orientation of the gradient vector. 


Fig.~\ref{fig:sampledescriptor} shows an example of a patch and a scheme of the histogram computation. Fig.~\ref{patch} is a plot of the signal and the patch centered in the keypoint. In Fig.~\ref{histogrambines} the possible orientations on each patch are illustrated. They form the corresponding $\mathbf{kp}$-descriptor of $128$ coordinates. The first two blocks are shown.  Following this procedure for every assigned keypoint, we obtain $N_{kp}$ descriptors.
 

 
\begin{figure}[H]
\centering
\subfigure[Plot of the signal, a keypoint and the corresponding patch.]{\includegraphics[width=.49\linewidth]{signalpatchkeypoint.png}\label{patch}}
\subfigure[Orientations on two blocks of the patch.]{\includegraphics[width=.49\linewidth]{histogramsbines.png}\label{histogrambines}}
%\includegraphics[width=9cm]{gradientszoom.png}
\caption{ Example of a patch and a scheme of the orientation's histogram computation.}
\label{fig:sampledescriptor}
\end{figure}

\subsubsection{Speller Matrix letter Identification}
\label{Classification}

%The following step is classify the descriptors $\{d_{kp}, kp =1,\dots, 12\}$ in order to determine the correct row and column of the chosen letter on the Speller Matrix.   The classification is carried out by using a discriminative semi-supervised classification method, based on the Naive Bayes Nearest Neighbor (NBNN)~\citep{Boiman2008}.

The aim is to identify the selected letter from the matrix. Previously, during training phase, two descriptors are extracted from averaged signal segments which correspond to the letter where the user was supposed to be focusing onto.  These descriptors are the P300 templates which are grouped in a template set called $ T $.  Segments corresponding to rows are labeled 1-6, whereas those corresponding to columns are labeled 7-12.  The process has the following steps:


\begin{enumerate}
\item \label{paso1}Highlight randomly the rows and columns from the matrix.  There is one row and one column that should match the letter selected by the subject.
\item  \label{paso2} Repeat step~\ref{paso1} $k_a$ times, obtaining the single trial segments $S_1(n,c),\dots,S_{k_a}(n,c)$, where the variables $n \in \{1, \dots, n_{max}\}$ and $c \in \{1,2,\dots,Ch\}$ correspond to time and channel, respectively. The parameter $k_a$ is the number of repetitions and it is an input parameter of the algorithm.
\item \label{paso3} Compute the Ensemble Average by
\begin{equation}
x(n,c)= \frac{1}{k_a}\sum_{i=1}^{k_a}S_i(n,c),n \in \{1, \dots, n_{max}\}, c \in \{1,\dots,Ch\}
\label{averaging}
\end{equation}  
for each row and column. 

\item \label{paso4}Plot the signal $x(n,c)$,  $n \in \{1, \dots, n_{max}\}$, $c \in \{1,\dots,Ch\}$,  according Section~\ref{Plot}. 

\item Repeat steps~\ref{paso2}, \ref{paso3} and~\ref{paso4} in order to generate the images $I^{row}_1, \dots, I^{row}_6$ and $I^{col}_7,\dots,I^{col}_{12}$ for rows and columns, respectively. 

\item Obtain the descriptors $ d^{row}_1, \dots,  d^{row}_6 $  and  $ d^{col}_7, \dots,  d^{col}_{12} $ for rows and columns, respectively from $I^{row}_1, \dots, I^{row}_6$ and $I^{col}_7,\dots,I^{col}_{12}$  in accordance to the method described in Section~\ref{SIFT}. 

\item Match to the Template $T$ by computing  

\begin{equation}
\hat{row} = \arg \min_{u \in \{1,\dots,6\}} \sum_{q \in NN_T(d^{row}_u)}^{} \left\lVert q -  d^{row}_u \right\rVert ^2
\label{eq:multiclassificationrow}
\end{equation}

\noindent and

\begin{equation}
\hat{col} = \arg \min_{u \in \{7,\dots,12\}} \sum_{q \in NN_T(d^{col}_u)}^{} \left\lVert q -  d^{col}_u \right\rVert ^2
\label{eq:multiclassificationcol}
\end{equation}

where $NN_T(d^l_u), \;l\in\{row,{col}\}$ is the set of the $k$ nearest neighbors to $d^l_u, \;l\in\{row,{col}\}$ and $q$ is a template descriptor that belongs to $NN_T(d^l_u), \;l\in\{row,{col}\}$.  

% By reversing the roles of the query and the class in equations \ref{eq:multiclassificationrow} and \ref{eq:multiclassificationcol}, it is only necessary to obtain the template set $ T $ with the learned descriptors representative of the P300 ERP, hence avoiding the problem of unbalanced classes. 
%The first step consists in extracting labeled \textit{hit} descriptors from the training set which are thus grouped together in a KD-tree \citep{Vedaldi2010} template set $ T $.  On decoding stage, 12 new images from the signal segments are generated, and their descriptors extracted.  The 12 descriptors are divided in rows and columns.  For each one of the 6 query descriptors $ q $ for row/column, its $ k $ nearest neighbours in the template set $T$, $ NN_T^k(q) $ (acquired during the training phase)  are obtained and the distance between each one of them, $ x_i $, and the query descriptor $ q $ is summarized.  The query descriptor $ q $ that minimizes this summation is the one that is chosen, first among the 6 rows, and then among the remaining 6 columns.  By performing this procedure, the correct letter can be identified by matching the row $ r $ and column $ c $ from the P300 speller matrix.   

\end{enumerate}
By computing the aforementioned equations, the letter of the matrix can be determined from the intersection of the row $ \hat{row} $ and column $ \hat{col} $. 
Figure~\ref{fig:classification} shows a scheme of this process. 
\begin{figure}[htp]
\centering
\includegraphics[width=15cm]{classificationgraph.pdf}
\caption{Single trial segments $S_i$ are averaged for the 6 rows and 6 columns. From the averaged signal, the image of the signal plot is generated and each descriptor is computed.  By comparing each descriptor against the set of templates, the P300 ERP can be detected, and finally the desired letter from the matrix can be inferred.}
\label{fig:classification}
\end{figure}

%Este párrafo no se entiende nada
%------------------

%------------------
%In the case of the P300 response, the oddball paradigm requires that one of the stimuli be infrequent. Hence this forces the data to be unbalanced~\citep{Tibon2015}.  At the same time, the NBNN method suffers from biased classification on unbalanced classes~\citep{Fornoni2014}. %Para solucionar este problema, 


\subsection{Experimental Protocol} \label{Protocol}

To verify the validity of the proposed framework and method, the public dataset 008-2014~\citep{Riccio2013} published on the BNCI-Horizon website~\citep{Brunner2014} by  IRCCS Fondazione Santa Lucia, is used. Additionally, an own dataset with  the same experimental conditions is generated. Both of them are utilized to perform an offline BCI Simulation to decode the spelled words from the provided signals. 

The algorithm is implemented using  VLFeat~\citep{Vedaldi2010} Computer Vision libraries on MATLAB V2014a (Mathworks Inc., Natick, MA, USA). 

In the following sections the characteristics of the datasets and parameters of the identification algorithm are described. 

\subsubsection{P300 ALS Public Dataset} \label{ALSDataset}

The experimental protocol used to generate this dataset is explained in~\citep{Riccio2013} but can be summarized as follows:  8 subjects with confirmed diagnoses but on different stages of ALS disease, were recruited and accepted to perform the experiments. The P300 detection task designed for this experiment consisted of spelling 7 words of 5 letters each, using the traditional P300 Speller Matrix~\citep{Farwell1988}. The flashing of rows and columns provide the deviant stimulus required to elicit this physiological response.  The first 3 words are used for training and the remaining 4 words, for testing with visual feedback.  A trial, as defined by the BCI2000 platform~\citep{Schalk2004}, is every attempt to select a letter from the speller. It is composed of signal segments corresponding to $k_a =10$ repetitions of flashes of 6 rows and $k_a =10$ repetitions of flashes of 6 columns of the matrix, yielding 120 repetitions.  Flashing of a row or a column is performed for 0.125 s, following by a resting period (i.e. inter-stimulus interval) of the same length.  After 120 repetitions an inter-trial pause is included before resuming with the following letter.

The recorded dataset was sampled at 256 Hz and it consisted of scalp EEG matrix for electrode channels Fz,Cz,Pz,Oz,P3,P4,PO7 and PO8, identified according to the 10-20 International System,  for each one of the 8 subjects.   The recording device was a research-oriented digital EEG device (g.Mobilab, g.Tec, Austria) and the data acquisition and stimuli delivery were handled by the BCI2000 open source software~\citep{Schalk2004}.

In order to asses and verify the identification of the P300 response, subjects are instructed to perform a copy-spelling task. They have to fix their attention to successive letters for copying a previously determined set of words, in contrast to a free-running operation of the speller where each user decides on its own what letter to choose.

\subsubsection{P300 for healthy subjects}

We replicate the same experiment on healthy subjects using a wireless digital EEG device (g.Nautilus, g.Tec, Austria).  The experimental conditions are the same as those used for the previous dataset, as detailed in section~\ref{ALSDataset}.

Participants are recruited voluntarily and the experiment is conducted anonymously in accordance with the declaration of Helsinki published by the World Health Organization.  No monetary compensation is handed out and all participants agree and sign a written informed consent.  All healthy subjects have normal or corrected-to normal vision and no history of neurological disorders. The experiment is performed with 8 subjects, 6 males, 2 females, 6 right-handed, 2 left-handed, average age 28.25 years, standard deviation  9.58 years, range 20-50 years.

EEG data is collected in a single recording session. Participants are seated in a comfortable chair, with their vision aligned to a computer screen located one meter in front of them.  The handling and processing of the data and stimulations is conducted by the OpenVibe platform~\citep{Renard2010}. 

Gel-based active electrodes (g.LADYbird, g.Tec, Austria) are used on the same locations Fz, Cz, Pz, P3,P4, Oz, PO7 and PO8.  Reference is set to the right ear lobe and ground is preset as the AFz position.   Sampling frequency is slightly different, and is set to 250 Hz, which is the closest possible to the one used with the other dataset.

%Fz, Cz, P3, Pz, P4, PO7, PO8 and Oz. 

%8 gel-based active electrodes (g.LADYbird) + g.LADYbird (GND) + g.GAMMAearclip (REF) C3, Cz, C4, CPz, P3, Pz, P4, POz, GND: AFz, REF: right ear

\subsubsection{Parameters}

The patch size is $S_P = 4.3s \times 4.3s$ pixels, where $s$ is the scale of the local patch and it is an input parameter of the algorithm. The P300 event can have a span of $400$ ms and its amplitude can reach $ 10 \mu V $~\citep{Rao2013}.  Hence it is necessary to utilize a size patch $S_P$ that could capture an entire transient event. With this purpose in consideration, the $s$ value election is essential.

%necesitamos definir el valor de s en función de los parámetros de la señal, de modo tal que el parche cubra el evento completo.  
We propose the Equations~\ref{eq:mapping2} and~\ref{eq:mapping1} to compute the scale value in horizontal and vertical directions, respectively. 
\begin{equation}
s_x = \frac{\lambda \cdot Fs}{4 \cdot 3} \cdot \gamma
\label{eq:mapping2}
\end{equation}

\begin{equation}
s_y= \frac{\Delta \mu V}{4 \cdot 3} \cdot \gamma 
\label{eq:mapping1}
\end{equation}


\noindent where $ \lambda $ is the length in seconds covered by the patch, $ Fs $ is the sampling frequency of the EEG signal (downsampled to 16 Hz) and  $\Delta  \mu V $ corresponds to the amplitude in microvolts that can be covered by the height of the patch. The geometric structure of the patch forces a squared configuration, then we discerned that by using $ s =s_x =s_y = 3 $ and $ \gamma = 4 $  the local patch and the descriptor can identify events of 9 $ \mu V $ of amplitude, with a span of $ \lambda = 0.56$ seconds.  This also provides that $ 1 $ pixel represents $ \frac{1}{\gamma}= \frac{1}{4} \mu V $ on the vertical direction and $\frac{1}{F_s.\gamma}=\frac{1}{64}$ seconds on the horizontal direction. Descriptors  $\mathbf{kp}$  are located at $ (x_{kp}, y_{kp} )= ( 0.55 Fs.\gamma, z(c) )= (35,  z(c)) $ for the corresponding channel $c$ (see Eq.~\ref{eq:zerolevel}).   In this way the whole transient event is captured. 
Figure~\ref{fig:sampledescriptor2} shows a patch of a signal plot covering the complete amplitude (vertical direction) and the complete span of the signal event (horizontal direction). 

\begin{figure}[H]
\centering
\includegraphics[width=10cm]{patchgeometry.pdf}
\caption{The scale of local patch is selected in order to capture the whole transient event.  The size of the patch is $S_p \times S_p$ pixels. The vertical size consists of $4$ blocks of size $3 s_y$ pixels which is long enough as to contain the signal $\Delta  \mu V $, the peak-to-peak amplitude of the transient event. The horizontal size on the other hand, includes $4$ blocks  of $3 s_x$ and covers the entire duration in seconds of the transient signal event, $ \lambda $.   }

\label{fig:sampledescriptor2}
\end{figure}

Lastly, the number of channels $Ch$ is equal to $8$ for both datasets, and the number of intensification sequences $k_a$ is statically assigned to $10$.  The parameter $k$ used in the Near Neighbor $NN_T(d^l_u), \;l\in\{row,{col}\}$ is set to $k=7$, following the suggestion of the article~\citep{Boiman2008}.  In addition, the norm used on  Equations \ref{eq:multiclassificationrow} and \ref{eq:multiclassificationcol} was the cosine norm, and descriptors were normalized to $ \left[ -1, 1 \right] $.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results and Discussion} \label{Results}
\label{section:results}

%In Figure \ref{fig:subjectaveraged} the grand average (point-to-point) for all the subjects using the information from all the segments can be shown.  The P300 characteristic curve can be seen particularly in subjects 2, and 6 and in a lesser extend in the remaining subjects. In order to correctly decode the selected letter from each trial, particular care was observed to avoid unbalanced number of epochs  (i.e. an unequal number of epochs on each condition), because that may introduce bias in the classification procedure (the variance of averaged signals is inversely proportional to the number of samples and the procedure would be discriminating signals with different variances).  
%
%\begin{figure}[H]
%\centering
%\includegraphics[width=16cm]{subjectaveraged.eps}
%\caption{Point-to-point grand averages of epochs obtained for hits (solid line) and no hits (dashed line) for each one of the 8 subjects for channel Cz. The P300 characteristic curve can be well identified particularly on subjects 2 and 6.}
%\label{fig:subjectaveraged}
%\end{figure}

The P300 ERP  consists of two overlapping components: the P3a and P3b, the former with frontocentral distribution while the later stronger on centroparietal region~\citep{Polich2007} then, the classical approach finds the stronger response on the central channel Cz~\citep{Riccio2013}. However, Wolpaw et al~\citep{Krusienski2006} show that the response may also arise in occipital channels.  In our approach, occipital channels PO8 and PO7 show higher performances for some subjects. %For example in the articles~\citep{Huggins2016,Jure2016} the authors show that channels PO8 and PO7 have higher performances.

%The authors~\citep{Riccio2013} that analyzed the public dataset concluded that Cz is the best performing channel, more representative of the difference in amplitudes. However, in our approach, occipital channels,  PO8 and PO7 show higher performances~\citep{Huggins2016,Jure2016}.

Table~\ref{tab:results} shows the results of applying the algorithm to the subjects of the public dataset of ALS patients~\citep{Riccio2013}. The percentage of correctly spelled letters is calculated while performing an offline BCI Simulation.  From the seven words for each subject, the first three are used as training, and the remaining four for testing.  The best performing channel is informed as well. The chance level is $2\%$.  It can be observed that the best performance of the letter identification method is reached in various channels depending on the subject on study. 

\begin{table}[H]
\caption{Percentage of correctly predicted letters while performing an offline BCI Simulation for the best performing channel for each subject of the public dataset 008-2014. Twenty letters, four words of five letters each, were used for testing. }
\centering
%% \tablesize{} %% You can specify the fontsize here, e.g.  \tablesize{\footnotesize}. If commented out \small will be used.
\begin{tabular}{ccc}
\toprule
\textbf{Participant}	&  \textbf{BPC}	& \textbf{Performance}\\
\midrule
1     &     Cz   &   $35\%$  \\
2     &     Fz   &   $85\%$  \\
3     &     Cz   &   $25\%$  \\
4     &     PO8 &   $55\%$  \\
5     &     PO7 &   $40\%$ \\
6     &     PO7 &   $60\%$  \\
7     &     PO8 &   $80\%$  \\
8     &     PO7 &   $95\%$ \\

\bottomrule
\end{tabular}
\label{tab:results}
\end{table}

In Table~\ref{tab:resultsowndataset} results obtained for 8 healthy subjects are shown.   These results were obtained by the present method as described in previous sections.  

%We used an additional subject as control as he was instructed to count only the letters and to stare at the screen but  neglecting row/column flashing, which achieved zero performance.  We also validated the procedure by visualizing clearly the SSVEP generated by the 4 Hz flashings.

\begin{table}[H]
\caption{Percentage of correctly predicted letters while performing an offline BCI Simulation for the best performing channel for each healthy subject. The method is applied on a channel by channel basis, and the best performing channel is shown. }
\centering
%% \tablesize{} %% You can specify the fontsize here, e.g.  \tablesize{\footnotesize}. If commented out \small will be used.
\begin{tabular}{cccc}
\toprule
\textbf{Participant}	&  \textbf{BPC}	& \textbf{Performance}\\
\midrule
1     &     Oz   &     $40\%$  \\
2     &     PO7   &     $30\%$ \\
3     &     P4   &     $40\%$ \\
4     &     P4   &     $45\%$ \\
5     &     P4   &      $60\%$ \\
6     &     Pz   &      $50\%$ \\
7     &     PO7   &      $70\%$ \\
8     &     P4   &      $50\%$ \\

\bottomrule
\end{tabular}
\label{tab:resultsowndataset}
\end{table}


The Information Transfer Rate (ITR), or Bit Transfer Rate (BTR), in the case of reactive BCIs~\citep{WolpawJonathanR2012}  depends on the amount of signal averaging required to transmit a valid and robust selection.  Fig.~\ref{fig:performance} shows the performance curves for varying intensification sequences. It can be observed that the percentage of correctly identified letters depends on the number of intensification sequences $k_a$ that are used to obtain the averaged signal.


\begin{figure}[H]
\centering
\includegraphics[width=10cm]{performance2.eps}
\caption{Performance curves for the eight subjects included in the dataset of ALS patients.  Three out of eight subjects achieved the necessary performance to implement a valid P300 speller.}
\label{fig:performance}
\end{figure}

As can be seen in the figure, as the number of intensification sequences tend to 1, which corresponds to single trial letter identification, the performance is reduced. As mentioned before, the SNR of the single trial P300 is very low. The ensemble average is carried out in order to improve the SNR but other problems arise, for example inter-trial variability due to latencies shifts that may produce an unstable P300 signature. To solve this problem, we tested an approach to assess if the morphological shape of the P300 can be stabilized by applying different shifts and we verified that there is a better performance when a correct resynchronization is applied, but results are still in process.  We also applied Dynamic Time Warping (DTW)~\citep{Casarotto2005} but we were unable to find a substantial improvement.     On the other hand amplitude, width and latency are generally affected by habituation, fatigue or level of attention and may lead to null signals\citep{Ouyang2017}. This is another source of instability of the P300 signature component that may need to be addressed.

As subjects may have different \textit{latencies}, \textit{amplitudes} and \textit{width} of their P300 components, they may also have distinct \textit{shapes} of the generated ERP.  Figure~\ref{fig:p300templates} shows the P300 templates patches for patients 8 and 3 from the public dataset. It can be observed that in coincidence with the performance results, the P300 signature is more clear and consistent for subject 8 (Fig.~\ref{subject8})  while for subject 3 (Fig.~\ref{subject3}) the characteristic pattern is more difficult to perceive.

\begin{figure}[H]
\centering
\subfigure[Subject 8.]{\includegraphics[width=10cm]{subject8.png}\label{subject8}}
\subfigure[Subject 3.]{\includegraphics[width=10cm]{subject3.png}\label{subject3}}
\caption{P300 template patches for subjects 8 and 3. As traditional done in neuroscience research, downward is positive. }
\label{fig:p300templates}
\end{figure}

%\begin{itemize}
%\item Lo que pusimos antes de la sincronización de las señales apunta a la latencia.
%\item Por el lado de la amplitud, lo que hicimos fue ir por un lado conservador de llevar todo a varianza uno.
%\item Si bien el zscore nos ayuda también genera otro problema adicional que es el que ponemos en el texto (y por el cual con razón Juan me criticaba).

%\end{itemize}

%La estandarizacion produce dos efectos contrarios entre si, contrapues.

%Por un lado reduce el ruido y outliers
%por otro lado reduce aquellos p300 significativos positivos que ayudarian su identificacion.

Another problem is the amplitude variation of the P300. We propose an approach by standardizing the signal, shown in Eq.~\ref{eq:standarizedaverages}.  First, it has the effect of normalizing the peak-to-peak amplitude, moderating its variation. It has also the advantage of reducing noise that were not reduced by the averaging procedure.   It is important to remark that the signal variance depends on the number of single-trials used to compute it \citep{van2006signal}.  The standardizing process converts the signal to unit signal variance which makes it independent of the number $k_a$ of signals averaged.   This is another advantage of this approach.  On the downsize, the standardizing process reduces the amplitude of any significant P300 complex diminishing its automatic interpretation capability.

For both datasets, the experimental protocol uses a very short inter-stimulus interval which has the potential to increase the ITR but at the same time it reduces the amplitude of the P300 response, hence it may be more difficult to detect it~\citep{Rao2013}.  

%As an unexpected consequence, $15$ out of $20$ subject reported high ocular tiredness by using this configuration.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Discussion}
%
%This method, different from other methods which is based on the nonlinearity of the gradient of histograms which can be used to detect 
%
%
%is also based on how the image look like.
%
%SNR of p300 and how to detect it
%
%Check if you can use this to detect any kind of transient signal.
%
%Compare if it is possible with the descriptors from one subject, discriminate the others.  Transfer learning.
%
%Channal identification based on the metric distance between the bags
%
%Signal Averaging.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{conclusion}

%In this paper, a new unsupervised method to enhance evoked response by target stimuli in an oddball paradigm was presented. Only given the time indexes of rows/columns intensifications, the proposed algorithm estimates the main components of the P300 subspace by providing the best SNR. It was shown to efficiently improve the quality of the evoked responses by taking into account the signal and the noise, as opposed to principal component analysis, which only considers the signal. Using this method to enhance P300 subspace before the BCI classification task speeds up the BCI since less words are required to train the spatial filters and the linear classifier, given a certain percentage of good symbol prediction. Moreover, using this spatial enhancement significantly reduces the dimension of the feature vector used to predict words.

%RECORDAR CALIBRATION STEP

Among other applications of BCI analysis, the goal of the entire discipline is to provide communication assistance to people affected by neuro-degenerative diseases.

In this work, a method to detect transient P300 components from EEG signals based on their waveform characterization in digital time-space, is presented.  Additionally, its validity is evaluated using a public dataset of ALS patients and an own dataset of healthy subjects. The objective of this article is to explore new techniques of P300 automatic interpretation.  
We know that we have to keep working but the results are promising. 

The method works on a channel by channel basis; in this way the best performing channel can be identified and used it to reduce the number of required EEG electrodes, leading to the development of more ergonomic capturing device.

We observed that the shape of the wave is more stable in occipital channels, where the performance for identifying letters is higher.   % It is understood that for people suffering from ALS, even though this pathology do not harm the CNS, their brain signals do suffer slow and deteriorating changes that may lead to different EEG patterns alterations \citep{Nijboer2009,Riener2014}.  
It is important to evaluate if there is any correlation between the lower performance obtained for some subjects and the characterization of their ALS stage.  Although,  we did not find any evidence in terms of the shape digital signal and the best response was obtained for an ALS subject.  Moreover, this method can be used as an alternate BCI predictor.  

By analyzing the generated descriptors, a metric about the shape of the P300 response can also be derived.  

By means of the empirical experiments, we concluded that the stability of the P300 in terms of shape is crucial: synchronization averaging,  inter-stimulus interval,  montages, the signal to noise ratio and spatial filters can all of them affect the stability of the shape of the P300 ERP. 

In our opinion, the best application of this approach is that a closer collaboration with physicians can be fostered, because our method intent to imitate human visual observation.
Automatically classify those patterns in EEG that are specifically identified by their shapes (e.g. K-Complex, Vertex Waves, Positive Occipital Sharp Transient~\citep{Hartman2005}) is a prospect future work to be considered. We are currently working in unpublished material analyzing KComplex that also provide  assistance to physician to locate these EEG patterns, specially in long recording periods, frequent in sleep research.  
Additionally, it can be used for artifact removal which is performed on many occasions by visually inspecting the signal.  This is due to the fact that the descriptors are directly based on the signals behavior in shape domain.  In line with these applications,  it can be used to build a database~\citep{Chavarriaga2017} of descriptors and improve atlases~\citep{Hartman2005}.

We also want to solve the problem of signal stabilization by applying different shifts on the averaging procedure and another methods for obtaining a correct synchronization.  

%Finally, waveform analysis and the methods that can be used to analyze them is an area where active research can benefit greatly both, physicians who need to automate some of the tools and practices and Brain Computer Interfaces or automatic EEG processing by using the extensive knowledge body available for clinical practices~\citep{Cole2017}

%To further improve the performance of the P300-speller BCI, additional work should be considered. For instance, to better estimate the response evoked by target stimuli, a multi- stimuli model should be deemed by assuming that all the non- target stimuli – as well as the target stimuli – evoked specific responses. Finally, sensor selection should also be considered, in order to drastically reduce the number of required EEG electrodes, leading thus to a more ergonomic BCI.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Subsection}
%
%\subsubsection{Subsubsection}
%
%Bulleted lists look like this:
%\begin{itemize}[leftmargin=*,labelsep=4mm]
%\item	First bullet
%\item	Second bullet
%\item	Third bullet
%\end{itemize}
%
%Numbered lists can be added as follows:
%\begin{enumerate}[leftmargin=*,labelsep=3mm]
%\item	First item
%\item	Second item
%\item	Third item
%\end{enumerate}
%
%The text continues here.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\supplementary{The following are available online at www.mdpi.com/link, Figure S1: title, Table S1: title, Video S1: title.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\acknowledgments{This project was supported by the ITBACyT-15 funding program issued by ITBA University. The authors would like to thank Dr. Juliana Gambini for their insights and help with the detailed description of the histogram of gradients.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\conflictofinterests{The authors declare that there is no conflict of interest regarding the publication of this article.} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
\abbreviations{The following abbreviations are used in this manuscript:\\

\noindent EEG: Electroencephalography\\
BCI: Brain Computer Interfaces\\
SNR: Signal to Noise Ratio\\
CNS: Central Nervous System\\
ALS: Amyotrophic Lateral Sclerosis\\
ERP: Event-Related Potential\\
P300: Positive deflection of an Event-Related Potential which occurs 300 ms after onset of stimulus\\
ITR: Information Transfer Rate\\
BTR: Bit Transfer Rate\\
SIFT: Scale Invariant Feature Transform\\
NBNN: Naive Bayes Nearest Neighbor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\appendixtitles{no} %Leave argument "no" if all appendix headings stay EMPTY (then no dot is printed after "Appendix A"). If the appendix sections contain a heading then change the argument to "yes".
%\appendixsections{multiple} %Leave argument "multiple" if there are multiple sections. Then a counter is printed ("Appendix A?). If there is only one appendix section then change the argument to ?one? and no counter is printed (?Appendix?).
%\appendix
%\section{}
%The appendix is an optional section that can contain details and data supplemental to the main text. For example, explanations of experimental details that would disrupt the flow of the main text, but nonetheless remain crucial to understanding and reproducing the research shown; figures of replicates for experiments of which representative data is shown in the main text can be added here if brief, or as Supplementary data. Mathemtaical proofs of results not central to the paper can be added as an appendix.
%
%\section{}
%All appendix sections must be cited in the main text. In the appendixes, Figures, Tables, etc. should be labeled starting with `A', e.g., Figure A1, Figure A2, etc. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here. 
\bibliographystyle{mdpi}

%=====================================
% References, variant A: internal bibliography
%=====================================
%\renewcommand\bibname{References}
%\begin{thebibliography}{999}
% Reference 1
%\bibitem{ref-journal}
%Lastname, F.; Author, T. The title of the cited article. {\em Journal Abbreviation} {\bf 2008}, {\em 10}, 142-149.
% Reference 2
%\bibitem{ref-book}
%Lastname, F.F.; Author, T. The title of the cited contribution. In {\em The Book Title}; Editor, F., Meditor, A., Eds.; Publishing House: City, Country, 2007; pp. 32-58.
%\end{thebibliography}

%=====================================
% References, variant B: external bibliography
%=====================================
\bibliography{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\sampleavailability{Samples of the compounds ...... are available from the authors.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}